{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "local-sessions",
   "metadata": {},
   "source": [
    "## I. Check rarity of getting 4/21'720 Bell's Palsy in 2 month assuming it's from normal population\n",
    "\n",
    "Modeling a distribution of ratio of people who have got an incidence of Bell's Palsy per year in a sample of size $n$, given that the population has incidence of  $23/100000\\,annually = 0.00023\\,annually = 0.023\\%\\,annually$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorporated-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from scipy import stats\n",
    "\n",
    "# annual incidence of Bell's palsy\n",
    "INCIDENCE = 0.00023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-origin",
   "metadata": {},
   "source": [
    "For hypothesis testing, we assume that null hypothesis is the following equality:\n",
    "\n",
    "$ H_0: k=np $  , where:\n",
    " - $k$ - number of occurences (successuful tests)\n",
    " - $n$ - number of trials\n",
    " - $p$ - probability of occurence (successful tests)\n",
    " - $np$ - mean (expected value) for the binomial distibution\n",
    " \n",
    " \n",
    " Calculating $p$-value (binomial test):\n",
    " \n",
    " $ Pr(X=k)=\\binom{n}{k}p^k(1-p)^{n-k} $\n",
    " \n",
    " Calculating $z$-score (for large samples, z-test):\n",
    " \n",
    " $ Z=\\frac{k-np}{\\sqrt{np(1-p)}} $\n",
    "\n",
    "Even though the samples sizes are large, the $H_0$ population probability is extremely small, insomuch that the expected value for $H_0$ populations are close to 0 and often less than 1. Therefore, we should not rely on the normal distribution to approximate such binomial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "included-montana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== vaccine group ===\n",
      "                        k1 = 4\n",
      "                        n1 = 21720\n",
      "                        p1 = 0.00383%\n",
      "\n",
      "    expected value = n1*p1 = 0.8326\n",
      "(scipy)              pval1 = 1.0385%\n",
      "(naive, binom. test) pval1 = 0.8707%\n",
      "                  s_error1 = 9.21e-05\n",
      "\n",
      "=== placebo group ===\n",
      "                        k2 = 0\n",
      "                        n2 = 21728\n",
      "                        p2 = 0.00383%\n",
      "\n",
      "    expected value = n2*p2 = 0.8326\n",
      "(scipy)              pval2 = 100.0%\n",
      "(naive, binom. test) pval2 = 43.4777%\n",
      "                  s_error2 = 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### binomial test for vaccine group ###\n",
    "print(\"=== vaccine group ===\")\n",
    "k1=4\n",
    "n1=21720\n",
    "p1=INCIDENCE/6 # assuming their study had average 2 months of screening\n",
    "\n",
    "print(f\"                        k1 = {k1}\")\n",
    "print(f\"                        n1 = {n1}\")\n",
    "print(f\"                        p1 = {round(p1*100, 5)}%\")\n",
    "print(\"\")\n",
    "\n",
    "expected1 = n1*p1\n",
    "print(f\"    expected value = n1*p1 = {round(expected1, 4)}\");\n",
    "\n",
    "# scipy\n",
    "pval1 = stats.binom_test(x=k1, n=n1, p=p1)\n",
    "print(f\"(scipy)              pval1 = {round(pval1*100, 4)}%\")\n",
    "\n",
    "# naive (binomial test)\n",
    "pval1 = math.comb(n1, k1) * math.pow(p1,k1) * math.pow(1-p1,n1-k1)\n",
    "print(f\"(naive, binom. test) pval1 = {round(pval1*100, 4)}%\")\n",
    "\n",
    "proportion1 = k1/n1\n",
    "s_error1 = math.sqrt((proportion1*(1-proportion1))/n1) # standard error for proportion\n",
    "print(f\"                  s_error1 = {round(s_error1,7)}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "### binomial test for placebo group ###\n",
    "print(\"=== placebo group ===\")\n",
    "k2=0\n",
    "n2=21728\n",
    "p2=INCIDENCE/6 # assuming their study had average 2 months of screening\n",
    "\n",
    "print(f\"                        k2 = {k2}\")\n",
    "print(f\"                        n2 = {n2}\")\n",
    "print(f\"                        p2 = {round(p2*100, 5)}%\")\n",
    "print(\"\")\n",
    "\n",
    "expected2 = n1*p1\n",
    "print(f\"    expected value = n2*p2 = {round(expected2, 4)}\");\n",
    "\n",
    "# scipy\n",
    "pval2 = stats.binom_test(x=k2, n=n2, p=p2)\n",
    "print(f\"(scipy)              pval2 = {round(pval2*100, 4)}%\")\n",
    "\n",
    "# naive (binomial test)\n",
    "pval2 = math.comb(n2, k2) * math.pow(p2,k2) * math.pow(1-p2,n2-k2)\n",
    "print(f\"(naive, binom. test) pval2 = {round(pval2*100, 4)}%\")\n",
    "\n",
    "proportion2 = k2/n2\n",
    "s_error2 = math.sqrt((proportion2*(1-proportion2))/n2) # standard error for proportion\n",
    "print(f\"                  s_error2 = {round(s_error2,7)}\")\n",
    "\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-safety",
   "metadata": {},
   "source": [
    "There are many methods for computing confidence intervals for proportions.\n",
    "\n",
    "The most used one is Wald Interval. E.g. for mean of sample the formula is the following:\n",
    "\n",
    "$95\\%CI_{\\bar{X}} = \\bar{X} \\pm z_{95}\\sigma_{\\bar{X}}$\n",
    "\n",
    "$99\\%CI_{\\bar{X}} = \\bar{X} \\pm z_{99}\\sigma_{\\bar{X}}$\n",
    "\n",
    "\n",
    "where standard error for sample mean is calculated as:\n",
    "\n",
    "$\\sigma_{\\bar{X}} = \\frac{\\sigma}{\\sqrt{n}}$, where $\\sigma$ is standard deviation and $n$ is sample size\n",
    "\n",
    "<br>\n",
    "Generally it's of this format:\n",
    "\n",
    "$95\\%CI_{y} = y \\pm z_{95}\\sigma_y$\n",
    "\n",
    "for some statistic $y$ and for it's standard error $\\sigma_y$ (i.e. standard deviation for $y$ as a measure in the population of measures $y$), where $z_{95}$ is a z-score from normal distribution for two-tailed test with $\\alpha$-level $0.05$ ($\\alpha$-level $0.01$ for $z_{99}$, and so on).\n",
    "\n",
    "In python, $z$-score can be calculated using _percent point function_ on the _normal distribution_ provided by a very famous library - _**scipy**_:\n",
    "\n",
    "```python\n",
    "from scipy.stats import norm\n",
    "\n",
    "def zScore_normal(conflevel: float = 0.95):\n",
    "    z: float = norm.ppf((1+conflevel)/2)\n",
    "    return abs(z)\n",
    "```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "In this case, for propotion the 99% CI is:\n",
    "\n",
    "$99\\%CI_{p_1} = p_1 \\pm z_{99}\\sigma_{p_1}$\n",
    "\n",
    "where $p_1$ is a propotion for the first group, and $\\sigma_{p_1}$ is standard error for propotion, $k$ is a number of successfull trials, and $n$ is a total number of trials:\n",
    "\n",
    "$p_1 = \\frac{k}{n}$\n",
    "\n",
    "$\\sigma_{p_1} = \\sqrt{\\frac{p_1(1-p_1)}{n}}$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "General form would look like:\n",
    "\n",
    "<p style=\"text-align: center; font-weight: bold\">Wald Interval</p>\n",
    "$$(w^-, w^+) = p\\,\\pm\\,z\\sqrt{\\frac{p(1-p)}{n}}$$\n",
    "Which computation can be implemented in Python:\n",
    "\n",
    "```python\n",
    "def wald_interval(x: int, n: int, conflevel: float = 0.95):\n",
    "    \"\"\"Calculates confidence interval for proportions using Wald Interval method\n",
    "    \n",
    "    `x` - succeeded trials\n",
    "    \n",
    "    `n` - total trials\n",
    "    \n",
    "    `conflevel` - confidence level (0 < float < 1)\n",
    "    \"\"\"\n",
    "    p = float(x)/n\n",
    "    sd = math.sqrt((p*(1-p))/n)\n",
    "    z = zScore_normal(conflevel)\n",
    "    z_sd = z*sd\n",
    "    ci = (\n",
    "        p - z_sd,\n",
    "        p + z_sd\n",
    "    )\n",
    "    return ci\n",
    "```\n",
    "<br>\n",
    "\n",
    "Wald Interval is known for its poor performance with low sample sizes ($n < 100$) or extreme proportions ($p$ close to $0$ or $1$).\n",
    "\n",
    "Since we have extremely low proportion values with big sample sizes, we can explore what is the best method to use to calculate CI.\n",
    "\n",
    "For this, let us pre-define a set of different true population proportions. For each of the true population proportions, let's simulate random sampling of size of $n$ trials $50000$ times, and see what part from the constructed CIs of all samples are actually covering (including) the true proportion. Ideally, for a 95% confidence interval, this coverage should be around 95%.\n",
    "\n",
    "\n",
    "> Source code for this simulation with all mentioned methods in Python:\n",
    "> \n",
    "> https://github.com/Kukuster/CI-for-proportions_methods_analysis\n",
    "> \n",
    "> The original code in R with explanations:\n",
    "> \n",
    "> https://towardsdatascience.com/five-confidence-intervals-for-proportions-that-you-should-know-about-7ff5484c024f\n",
    "\n",
    "Here is results of a simulation of actual coverage for 95%CI for the sample size of $100$ trials and for proportion values from $0.01$ to $0.99$ using Wald Interval method:\n",
    "\n",
    "![image](./wald_pfrom0.001_pto0.991_pstep0.01_trials100_samples50000_dark.png \"Wald Interval\")\n",
    "\n",
    "What we can see here, is that this method generally underperforms for proportions in range from $0.1$ to $0.9$, and performs terribly bad outside the range.\n",
    "\n",
    "In this way, simulating enough samples (like $50000$), we can practically compare how precise and how concervative are different methods for calculating confidence intervals for proportions.\n",
    "\n",
    "Let's take a look at the Wilson Score Interval:\n",
    "\n",
    "<p style=\"text-align: center; font-weight: bold\">Wilson Score Interval</p>\n",
    "$$(w^-, w^+) = \\frac{p + z^2/2n \\pm z\\sqrt{p(1-p)/n + z^2/4n^2}}{1+z^2/n}$$\n",
    "\n",
    "```python\n",
    "def wilson_score_interval(x: int, n: int, conflevel: float = 0.95):\n",
    "    \"\"\"Calculates confidence interval for proportions using Wilson Score Interval method\n",
    "    \n",
    "    `x` - succeeded trials\n",
    "    \n",
    "    `n` - total trials\n",
    "    \n",
    "    `conflevel` - confidence level (0 < float < 1)\n",
    "    \"\"\"\n",
    "    p = float(x)/n\n",
    "    z = zScore_normal(conflevel)\n",
    "    denom = 1 + ((z**2) / n)\n",
    "    mean = p + ((z**2)/(2*n))\n",
    "    diff = z * math.sqrt(p*(1-p)/n + (z**2)/(4*n**2))\n",
    "    ci = (\n",
    "        (mean-diff)/denom,\n",
    "        (mean+diff)/denom\n",
    "    )\n",
    "    return ci\n",
    "```\n",
    "\n",
    "Being a modern improvement on the Wald Interval, it's often used for small samples and extreme probabilities. It doesn't suffer nearly that much from producing a very narrow interval or expanding to close to 100%.\n",
    "\n",
    "![image](wsi_pfrom0.001_pto0.991_pstep0.01_trials100_samples50000_dark.png \"Wilson Score Interval\")\n",
    "\n",
    "We can't say with this, that it underperforms.\n",
    "\n",
    "People have gone even further, correcting for continuity.\n",
    "\n",
    "<p style=\"text-align: center; font-weight: bold\">Wilson Score Interval (continuity-corrected)</p>\n",
    "\n",
    "$$w_{cc}^- = \\frac{2np + z^2 - (z\\sqrt{z^2 - 1/n + 4np(1-p) + (4p-2)} + 1)}{2(n+z^2)}$$\n",
    "\n",
    "\n",
    "$$w_{cc}^+ = \\frac{2np + z^2 + (z\\sqrt{z^2 - 1/n + 4np(1-p) - (4p-2)} + 1)}{2(n+z^2)}$$\n",
    "\n",
    "or, simplified:\n",
    "\n",
    "$$e = 2np + z^2;\\,\\,\\, f = z^2 - 1/n + 4np(1-p);\\,\\,\\, g = (4p - 2);\\,\\,\\, h = 2(n+z^2)$$\n",
    "\n",
    "$$w_{cc}^- = \\frac{e - (z\\sqrt{f+g} + 1)}{h}$$ \n",
    "\n",
    "$$w_{cc}^+ = \\frac{e + (z\\sqrt{f-g} + 1)}{h}$$\n",
    "\n",
    "```python\n",
    "def wilson_score_interval_continuity_corrected(x: int, n: int, conflevel: float = 0.95):\n",
    "    \"\"\"Calculates confidence interval for proportions using Wilson Score Interval method with correction for continuity\n",
    "    \n",
    "    `x` - succeeded trials\n",
    "    \n",
    "    `n` - total trials\n",
    "    \n",
    "    `conflevel` - confidence level (0 < float < 1)\n",
    "    \"\"\"\n",
    "    p = float(x)/n\n",
    "    z = zScore_normal(conflevel)\n",
    "    e = 2*n*p + z**2\n",
    "    f = z**2 - 1/n + 4*n*p*(1-p)\n",
    "    g = (4*p - 2)\n",
    "    h = 2*(n+z**2)\n",
    "    ci = (\n",
    "        (e - (z*math.sqrt(f+g) + 1))/h,\n",
    "        (e + (z*math.sqrt(f-g) + 1))/h\n",
    "    )\n",
    "    return ci\n",
    "```\n",
    "\n",
    "![image](wsicc_pfrom0.001_pto0.991_pstep0.01_trials100_samples50000_dark.png \"Wilson Score Interval (continuity-corrected)\")\n",
    "\n",
    "Although the corrected method does deviate more from the 95% point, what it doesn't do, is underestimate the range. Because of that, many would prefer this method.\n",
    "\n",
    "Using this simulation, we can play around creating our own different methods. E.g. we might be interested in something like Wilson Score Interval with continuity correction, but not that concervative. Let's make up out own method.\n",
    "\n",
    "\n",
    "<p style=\"text-align: center; font-weight: bold\">Wilson Score Interval (continuity-semi-corrected)</p>\n",
    "$$(w_{sc}^-, w_{sc}^+) = (\\frac{w^- + w_{cc}^-}{2}, \\frac{w^+ + w_{cc}^+}{2})$$\n",
    "\n",
    "```python\n",
    "def wilson_score_interval_continuity_semicorrected(x: int, n: int, conflevel: float = 0.95):\n",
    "    \"\"\"Calculates confidence interval for proportions using two Wilson Score Interval methods\n",
    "    (arithmetic mean of ordinary and continuity-corrected methods)\n",
    "    \n",
    "    `x` - succeeded trials\n",
    "    \n",
    "    `n` - total trials\n",
    "    \n",
    "    `conflevel` - confidence level (0 < float < 1)\n",
    "    \"\"\"\n",
    "    uncorrected = wilson_score_interval(x, n, conflevel)\n",
    "    corrected   = wilson_score_interval_continuity_corrected(x, n, conflevel)\n",
    "    ci = (\n",
    "        (corrected[0]+uncorrected[0])/2,\n",
    "        (corrected[1]+uncorrected[1])/2\n",
    "    )\n",
    "    return ci\n",
    "```\n",
    "![image](wsisc_pfrom0.001_pto0.991_pstep0.01_trials100_samples50000_dark.png \"Wilson Score Interval (continuity-semicorrected)\")\n",
    "This looks better then the continuity-corrected Wilson Score Interval method for proportions in the range from 0.1 to 0.9. There's a good ballance between concervativism and accuracy. Basically, for most values of $p$ coverage stays in range from $94.5\\%$ to $97.5\\%$.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Using this code we can set up simulation more specifically for our hypothesised and observed proportions between $1\\cdot10^{-5}$ to $2\\cdot10^{-4}$, and samples sizes between $20000$ and $40000$.\n",
    "\n",
    "<div style=\"text-align: center; margin: auto\">\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wald_pfrom1e-06_pto0.000199_pstep0.000001_trials20000_samples50000_dark.png\" alt=\"coverage of 95%CI using Wald Interval for values of p from 1e-5 to 2e-4 and sample size 20000\" />\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wald_pfrom1e-06_pto0.000199_pstep0.000001_trials40000_samples50000_dark.png\" alt=\"coverage of 95%CI using Wald Interval for values of p from 1e-5 to 2e-4 and sample size 40000\" />\n",
    "</div>\n",
    "<div style=\"text-align: center; margin: auto\">\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wsi_pfrom1e-06_pto0.000199_pstep0.000001_trials20000_samples50000_dark.png\" alt=\"coverage of 95%CI using Wilson Score Interval for values of p from 1e-5 to 2e-4 and sample size 20000\" />\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wsi_pfrom1e-06_pto0.000199_pstep0.000001_trials40000_samples50000_dark.png\" alt=\"coverage of 95%CI using Wilson Score Interval for values of p from 1e-5 to 2e-4 and sample size 40000\" />\n",
    "</div>\n",
    "<div style=\"text-align: center; margin: auto\">\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wsicc_pfrom1e-06_pto0.000199_pstep0.000001_trials20000_samples50000_dark.png\" alt=\"coverage of 95%CI using continuity-corrected Wilson Score Interval for values of p from 1e-5 to 2e-4 and sample size 20000\" />\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wsicc_pfrom1e-06_pto0.000199_pstep0.000001_trials40000_samples50000_dark.png\" alt=\"coverage of 95%CI using continuity-corrected Wilson Score Interval for values of p from 1e-5 to 2e-4 and sample size 40000\" />\n",
    "</div>\n",
    "<div style=\"text-align: center; margin: auto\">\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wsisc_pfrom1e-06_pto0.000199_pstep0.000001_trials20000_samples50000_dark.png\" alt=\"coverage of 95%CI using continuity-semi-corrected Wilson Score Interval for values of p from 1e-5 to 2e-4 and sample size 20000\" />\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wsisc_pfrom1e-06_pto0.000199_pstep0.000001_trials40000_samples50000_dark.png\" alt=\"coverage of 95%CI using continuity-semi-corrected Wilson Score Interval for values of p from 1e-5 to 2e-4 and sample size 40000\" />\n",
    "</div>\n",
    "<br><br>\n",
    "\n",
    "Let's choose Wilson Score Interval and Wilson Score Interval continuity-semi-corrected\n",
    "\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<!-- <br><br><br><br><br><br>\n",
    "In our situation, we are interested in samples sizes in around range 20000-40000, and hypothesised probabilities in range from $1\\cdot10^{-5}$ to $2\\cdot10^{-4}$\n",
    "\n",
    "<div style=\"text-align: center; margin: auto\">\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wald_pfrom1e-06_pto0.000199_pstep0.000001_trials20000_samples50000_dark.png\" alt=\"coverage of 95%CI using Wald Interval for values of p from 1e-5 to 2e-4\" />\n",
    "    <img style=\"display: inline-block; margin: 5px\" src=\"./wald_pfrom1e-06_pto0.000199_pstep0.000001_trials20000_samples50000_dark.png\" alt=\"coverage of 95%CI using Wald Interval for values of p from 1e-5 to 2e-4\" />\n",
    "</div>\n",
    "\n",
    "<br><br> -->\n",
    "\n",
    "Let's calculate _standard error for proportion_ for both groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "silver-heating",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Standard error for proportions for vaccine group ===\n",
      "for:\n",
      "proportion1 = 0.00018, n1 = 21720\n",
      "SE_proportion1 = 9.2e-05\n",
      "\n",
      "=== Standard error for proportions for placebo group ===\n",
      "for:\n",
      "proportion2 = 0.0, n2 = 21728\n",
      "SE_proportion2 = 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from typing import Tuple, Union, List\n",
    "\n",
    "def zScore_normal(conflevel: float = 0.95):\n",
    "    z: float = norm.ppf((1+conflevel)/2)\n",
    "    return abs(z)\n",
    "\n",
    "\n",
    "def wilson_score_interval(x: int, n: int, conflevel: float = 0.95):\n",
    "    \"\"\"Calculates confidence interval for proportions using Wilson Score Interval method\n",
    "    \n",
    "    `x` - succeeded trials\n",
    "    \n",
    "    `n` - total trials\n",
    "    \n",
    "    `conflevel` - confidence level (0 < float < 1)\n",
    "    \"\"\"\n",
    "    p = float(x)/n\n",
    "    z = zScore_normal(conflevel)\n",
    "    denom = 1 + ((z**2) / n)\n",
    "    mean = p + ((z**2)/(2*n))\n",
    "    diff = z * math.sqrt(p*(1-p)/n + (z**2)/(4*n**2))\n",
    "    ci = (\n",
    "        (mean-diff)/denom,\n",
    "        (mean+diff)/denom\n",
    "    )\n",
    "    return ci\n",
    "\n",
    "def wilson_score_interval_continuity_corrected(x: int, n: int, conflevel: float = 0.95):\n",
    "    \"\"\"Calculates confidence interval for proportions using Wilson Score Interval method with correction for continuity\n",
    "    \n",
    "    `x` - succeeded trials\n",
    "    \n",
    "    `n` - total trials\n",
    "    \n",
    "    `conflevel` - confidence level (0 < float < 1)\n",
    "    \"\"\"\n",
    "    p = float(x)/n\n",
    "    z = zScore_normal(conflevel)\n",
    "    e = 2*n*p + z**2\n",
    "    f = z**2 - 1/n + 4*n*p*(1-p)\n",
    "    g = (4*p - 2)\n",
    "    h = 2*(n+z**2)\n",
    "    ci = (\n",
    "        (e - (z*math.sqrt(f+g) + 1))/h,\n",
    "        (e + (z*math.sqrt(f-g) + 1))/h\n",
    "    )\n",
    "    return ci\n",
    "\n",
    "def wilson_score_interval_continuity_semicorrected(x: int, n: int, conflevel: float = 0.95):\n",
    "    \"\"\"Calculates confidence interval for proportions using two Wilson Score Interval methods\n",
    "    (arithmetic mean of ordinary and continuity-corrected methods)\n",
    "    \n",
    "    `x` - succeeded trials\n",
    "    \n",
    "    `n` - total trials\n",
    "    \n",
    "    `conflevel` - confidence level (0 < float < 1)\n",
    "    \"\"\"\n",
    "    uncorrected = wilson_score_interval(x, n, conflevel)\n",
    "    corrected   = wilson_score_interval_continuity_corrected(x, n, conflevel)\n",
    "    ci = (\n",
    "        (corrected[0]+uncorrected[0])/2,\n",
    "        (corrected[1]+uncorrected[1])/2\n",
    "    )\n",
    "    return ci\n",
    "\n",
    "\n",
    "def pretty_CI_percent(ci: Tuple[float, float]) -> Tuple[str, str]:\n",
    "    frmt = lambda flt: '{0:.10f} %'.format(flt*100)\n",
    "    pretty_CI = (frmt(ci[0]), frmt(ci[1]))\n",
    "    return pretty_CI\n",
    "\n",
    "def std_err(p: float, n: int) -> float:\n",
    "    \"\"\"Calculates standard error for proportion\n",
    "    \n",
    "    p - proportion\n",
    "    \n",
    "    n - sample size\n",
    "    \"\"\"\n",
    "    return math.sqrt((p*(1-p)/n))\n",
    "\n",
    "print(\"=== Standard error for proportions for vaccine group ===\")\n",
    "SE_proportion1 = std_err(proportion1, n1)\n",
    "print(f\"for:\")\n",
    "print(f\"proportion1 = {round(proportion1, 5)}, n1 = {round(n1, 5)}\")\n",
    "print(f\"SE_proportion1 = {round(SE_proportion1,6)}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"=== Standard error for proportions for placebo group ===\")\n",
    "SE_proportion2 = std_err(proportion2, n2)\n",
    "print(f\"for:\")\n",
    "print(f\"proportion2 = {round(proportion2, 5)}, n2 = {round(n2, 5)}\")\n",
    "print(f\"SE_proportion2 = {round(SE_proportion2,6)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-elder",
   "metadata": {},
   "source": [
    "What's more important, is standard error for the difference between two population proportions:\n",
    "\n",
    "$\\sigma_{diff} = \\sqrt{\\sigma_{p_1}^2 + \\sigma_{p_2}^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aboriginal-distinction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Standard error for difference of proportions ===\n",
      "SE_proportions_diff = 9.2e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Standard error for difference of proportions ===\")\n",
    "\n",
    "SE_proportions_diff = math.sqrt(SE_proportion1**2 + SE_proportion2**2)\n",
    "print(f\"SE_proportions_diff = {round(SE_proportions_diff, 6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-fancy",
   "metadata": {},
   "source": [
    "<!-- Now we can calculate 95%CI and 99%CI for each sample, to figure out were their respective population proportion lies within for certain -->\n",
    "\n",
    "<< _The point of considering a confidence interval is that if the metric is the __relative risk__ and the 95\n",
    "percent CI includes 1.0, then any difference between treatments is probably due to chance (i.e.,\n",
    "the p value would be > 0.05), Similarly, if the metric is the __absolute difference__ and the 95 percent\n",
    "include 0.0, there is no real difference between treatments. However, the upper and lower limits\n",
    "of the confidence interval will give an indication of what the maximum and minimum\n",
    "differences might be and therefore a clinical judgment can be made about the importance of the\n",
    "difference if it exists._ >>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-rogers",
   "metadata": {},
   "source": [
    "Absolute risk difference (differenece between sample proportions):\n",
    "\n",
    "$r_{abs\\Delta} = \\frac{k_1}{n_1} - \\frac{k_2}{n_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "silver-august",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute_risk_difference = 0.000184\n"
     ]
    }
   ],
   "source": [
    "absolute_risk_difference = (k1/n1) - (k2/n2)\n",
    "print(f\"absolute_risk_difference = {round(absolute_risk_difference, 6)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-shark",
   "metadata": {},
   "source": [
    "Finally, lets calculate 95%CI and 99%CI for each proportion and for the absolute proportion difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fifty-stocks",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CI for proportion (vaccine group) ===\n",
      "proportion1_95CI = ('0.0071619287 %', '0.0473471177 %')\n",
      "proportion1_99CI = ('0.0054791992 %', '0.0618800429 %')\n",
      "\n",
      "=== CI for proportion (placebo group) ===\n",
      "proportion2_95CI = ('0.0000000000 %', '0.0176766374 %')\n",
      "proportion2_99CI = ('0.0000000000 %', '0.0305268372 %')\n",
      "\n",
      "=== CI for difference of proportion ===\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'z95' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fdac7d8c1e72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== CI for difference of proportion ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mproportions_diff_95CI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mabsolute_risk_difference\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mz95\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSE_proportions_diff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabsolute_risk_difference\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mz95\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSE_proportions_diff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mproportions_diff_95CI_pretty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'{0:.10f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproportions_diff_95CI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" %\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{0:.10f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproportions_diff_95CI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" %\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"proportions_diff_95CI = {proportions_diff_95CI_pretty}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z95' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"=== CI for proportion (vaccine group) ===\")\n",
    "proportion1_95CI = wilson_score_interval(k1, n1, 0.95)\n",
    "proportion1_95CI_pretty = pretty_CI_percent(proportion1_95CI)\n",
    "print(f\"proportion1_95CI = {proportion1_95CI_pretty}\")\n",
    "proportion1_99CI = wilson_score_interval(k1, n1, 0.99)\n",
    "proportion1_99CI_pretty = pretty_CI_percent(proportion1_99CI)\n",
    "print(f\"proportion1_99CI = {proportion1_99CI_pretty}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"=== CI for proportion (placebo group) ===\")\n",
    "proportion2_95CI = wilson_score_interval(k2, n2, 0.95)\n",
    "proportion2_95CI_pretty = pretty_CI_percent(proportion2_95CI)\n",
    "print(f\"proportion2_95CI = {proportion2_95CI_pretty}\")\n",
    "proportion2_99CI = wilson_score_interval(k2, n2, 0.99)\n",
    "proportion2_99CI_pretty = pretty_CI_percent(proportion2_99CI)\n",
    "print(f\"proportion2_99CI = {proportion2_99CI_pretty}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"=== CI for difference of proportion ===\")\n",
    "proportions_diff_95CI = (absolute_risk_difference - z95*SE_proportions_diff, absolute_risk_difference + z95*SE_proportions_diff)\n",
    "proportions_diff_95CI_pretty = ('{0:.10f}'.format(proportions_diff_95CI[0]*100)+\" %\", '{0:.10f}'.format(proportions_diff_95CI[1]*100)+\" %\")\n",
    "print(f\"proportions_diff_95CI = {proportions_diff_95CI_pretty}\")\n",
    "proportions_diff_99CI = (absolute_risk_difference - z99*SE_proportions_diff, absolute_risk_difference + z99*SE_proportions_diff)\n",
    "proportions_diff_99CI_pretty = ('{0:.10f}'.format(proportions_diff_99CI[0]*100)+\" %\", '{0:.10f}'.format(proportions_diff_99CI[1]*100)+\" %\")\n",
    "print(f\"proportions_diff_99CI = {proportions_diff_99CI_pretty}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-judge",
   "metadata": {},
   "source": [
    "Interestingly enought, 95%CI indicating statistically significant effect may represent public concern regarding the data about BP.\n",
    "\n",
    "Indeed, 99%CI has to be much more appropriate to assume here, because there are plenty of other diseases that could spike to such difference.\n",
    "\n",
    "99%CI for difference of proportions including zero indicates statistically insignificant difference between two proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-mention",
   "metadata": {},
   "source": [
    " ## II. Check rarity of getting a sample of 37'706 people with 0.3% (118) prevalence of rheumatic diseases from a normal population (about 1.5% prevalence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-saying",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "PREVALENCE = 0.015\n",
    "\n",
    "### binomial test ###\n",
    "k=118\n",
    "n=37706\n",
    "\n",
    "print(f\"PREVALENCE = {PREVALENCE}\");\n",
    "print(f\"         k = {k}\")\n",
    "print(f\"         n = {n}\")\n",
    "print(\"\")\n",
    "expected = n*PREVALENCE\n",
    "print(f\"expected value = n*PREVALENCE = {round(expected, 4)}\");\n",
    "\n",
    "proportion=k/n\n",
    "\n",
    "pval = stats.binom_test(x=k, n=n, p=PREVALENCE)\n",
    "print(f\"    pval = {pval}\")\n",
    "\n",
    "s_error = math.sqrt((proportion*(1-proportion))/n) # standard error for proportion\n",
    "print(f\" s_error = {round(s_error,7)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-projector",
   "metadata": {},
   "source": [
    "For prevalence $1.5\\%$ the resulting $p$-value ranges somewhere between $10^{-117}$ to $10^{-116}$ depending on the calculation\n",
    "\n",
    "For prevalence $1.2\\%$: $p$-value $=$ from $10^{-79}$ to $10^{-78}$\n",
    "\n",
    "For prevalence $1\\%$: $p$-value $=$ from $10^{-55}$ to $10^{-54}$\n",
    "\n",
    "So that's unmeasurably small numbers.\n",
    "\n",
    "\n",
    "What are the possible adequate prevalence for the biased population from which people were picked?\n",
    "\n",
    "For prevalence $0.8\\%$: $p$-value $=$ from $10^{-34}$ to $10^{-33}$\n",
    "\n",
    "For prevalence $0.6\\%$: $p$-value $=$ from $10^{-16}$ to $3\\cdot10^{-15}$\n",
    "\n",
    "For prevalence $0.5\\%$: $p$-value $=$ from $10^{-8}$ to $4\\cdot10^{-8}$\n",
    "\n",
    "For prevalence $0.4\\%$: $p$-value $= 0.006239 = 0.6239\\%$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-talent",
   "metadata": {},
   "source": [
    "Another way to assess possible prevalence for the biased population would be to calculate CI for proportion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-swaziland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"=== CI for proportion of people with rheumatic disease ===\")\n",
    "rheu_proportion_95CI = (proportion - z95*s_error, proportion + z95*s_error)\n",
    "rheu_proportion_95CI_pretty = ('{0:.10f}'.format(rheu_proportion_95CI[0]*100)+\" %\", '{0:.10f}'.format(rheu_proportion_95CI[1]*100)+\" %\")\n",
    "print(f\"rheu_proportion_95CI = {rheu_proportion_95CI_pretty}\")\n",
    "rheu_proportion_99CI = (proportion - z99*s_error, proportion + z99*s_error)\n",
    "rheu_proportion_99CI_pretty = ('{0:.10f}'.format(rheu_proportion_99CI[0]*100)+\" %\", '{0:.10f}'.format(rheu_proportion_99CI[1]*100)+\" %\")\n",
    "print(f\"rheu_proportion_99CI = {rheu_proportion_99CI_pretty}\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-findings",
   "metadata": {},
   "source": [
    "## III. If step II rarity is significant then assume their sample is indeed from a biased distribution and has 0.3% prevalence of rheumatic diseases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-solution",
   "metadata": {},
   "source": [
    "We can safely now use the number $0.3\\%$ for the biases population prevalence of rheumatic disease. Or we can toughly round the number towards less effect to $0.4\\%$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-breathing",
   "metadata": {},
   "source": [
    "## IV. Extrapolate the bias towards people with less rheumatic disease to the bias towards less allergic/autoimmune disease of their sample to a new expected incidence of Bell's palsy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-statement",
   "metadata": {},
   "source": [
    "Naively, this can be done by taking the same bias proportion to the BP incidence as it is for rheumatic disease prevalence.\n",
    "\n",
    "That is, if the world population has about $1.2\\%$ prevalence of rheumatic disease, then:\n",
    "\n",
    "$0.023\\% \\cdot \\frac{0.4\\%}{1.2\\%} = 0.023\\% : 3 = 0.0077\\% = 0.000077$\n",
    "\n",
    "Assuming incidence of Bell's palsy in a biased population to be $0.0077\\%$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-baking",
   "metadata": {},
   "source": [
    "## V. Check rarity of getting 4/21'720 Bell's Palsy in 2 month assuming it's from the biased distribution from step III (assuming extrapolation from IV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-consortium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INCIDENCE_biased = 0.000077\n",
    "\n",
    "### binomial test for vaccine group ###\n",
    "print(\"=== vaccine group ===\")\n",
    "k1=4\n",
    "n1=21720\n",
    "p1=INCIDENCE_biased/6 # assuming their study had average 2 months of screening\n",
    "\n",
    "print(f\"                        k1 = {k1}\")\n",
    "print(f\"                        n1 = {n1}\")\n",
    "print(f\"                        p1 = {round(p1*100, 5)}%\")\n",
    "print(\"\")\n",
    "\n",
    "expected1 = n1*p1\n",
    "print(f\"    expected value = n1*p1 = {round(expected1, 4)}\")\n",
    "\n",
    "# scipy\n",
    "pval1 = stats.binom_test(x=k1, n=n1, p=p1)\n",
    "print(f\"(scipy)              pval1 = {round(pval1*100, 4)}%\")\n",
    "\n",
    "# naive (binomial test)\n",
    "pval1 = math.comb(n1, k1) * math.pow(p1,k1) * math.pow(1-p1,n1-k1)\n",
    "print(f\"(naive, binom. test) pval1 = {round(pval1*100, 4)}%\")\n",
    "\n",
    "proportion1 = k1/n1\n",
    "s_error1 = math.sqrt((proportion1*(1-proportion1))/n1) # standard error for proportion\n",
    "print(f\"                  s_error1 = {round(s_error1,7)}\")\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "### binomial test for placebo group ###\n",
    "print(\"=== placebo group ===\")\n",
    "k2=0\n",
    "n2=21728\n",
    "p2=INCIDENCE_biased/6 # assuming their study had average 2 months of screening\n",
    "\n",
    "print(f\"                        k2 = {k2}\")\n",
    "print(f\"                        n2 = {n2}\")\n",
    "print(f\"                        p2 = {round(p2*100, 5)}%\")\n",
    "print(\"\")\n",
    "\n",
    "expected2 = n2*p2\n",
    "print(f\"    expected value = n2*p2 = {round(expected2, 4)}\")\n",
    "\n",
    "# scipy\n",
    "pval2 = stats.binom_test(x=k2, n=n2, p=p2)\n",
    "print(f\"(scipy)              pval2 = {round(pval2*100, 4)}%\")\n",
    "\n",
    "# naive (binomial test)\n",
    "pval2 = math.comb(n2, k2) * math.pow(p2,k2) * math.pow(1-p2,n2-k2)\n",
    "print(f\"(naive, binom. test) pval2 = {round(pval2*100, 4)}%\")\n",
    "\n",
    "proportion2 = k2/n2\n",
    "s_error2 = math.sqrt((proportion2*(1-proportion2))/n2) # standard error for proportion\n",
    "print(f\"                  s_error2 = {round(s_error2,7)}\")\n",
    "\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "SE_proportion1 = s_error1\n",
    "SE_proportion2 = s_error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-sympathy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"=== Standard error for difference of proportions ===\")\n",
    "\n",
    "SE_proportions_diff = math.sqrt(math.pow(SE_proportion1,2) + math.pow(SE_proportion2,2))\n",
    "print(f\"SE_proportions_diff = {round(SE_proportions_diff, 6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-confidence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "absolute_risk_difference = (k1/n1) - (k2/n2)\n",
    "print(f\"absolute_risk_difference = {round(absolute_risk_difference, 6)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-august",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"=== CI for proportion (vaccine group) ===\")\n",
    "proportion1_95CI = (proportion1 - z95*SE_proportion1, proportion1 + z95*SE_proportion1)\n",
    "proportion1_95CI_pretty = ('{0:.10f}'.format(proportion1_95CI[0]*100)+\" %\", '{0:.10f}'.format(proportion1_95CI[1]*100)+\" %\")\n",
    "print(f\"proportion1_95CI = {proportion1_95CI_pretty}\")\n",
    "proportion1_99CI = (proportion1 - z99*SE_proportion1, proportion1 + z99*SE_proportion1)\n",
    "proportion1_99CI_pretty = ('{0:.10f}'.format(proportion1_99CI[0]*100)+\" %\", '{0:.10f}'.format(proportion1_99CI[1]*100)+\" %\")\n",
    "print(f\"proportion1_99CI = {proportion1_99CI_pretty}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"=== CI for proportion (placebo group) ===\")\n",
    "proportion2_95CI = (proportion2 - z95*SE_proportion2, proportion2 + z95*SE_proportion2)\n",
    "proportion2_95CI_pretty = ('{0:.10f}'.format(proportion2_95CI[0]*100)+\" %\", '{0:.10f}'.format(proportion2_95CI[1]*100)+\" %\")\n",
    "print(f\"proportion2_95CI = {proportion2_95CI_pretty}\")\n",
    "proportion2_99CI = (proportion2 - z99*SE_proportion2, proportion2 + z99*SE_proportion2)\n",
    "proportion2_99CI_pretty = ('{0:.10f}'.format(proportion2_99CI[0]*100)+\" %\", '{0:.10f}'.format(proportion2_99CI[1]*100)+\" %\")\n",
    "print(f\"proportion2_99CI = {proportion2_99CI_pretty}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"=== CI for difference of proportions ===\")\n",
    "proportions_diff_95CI = (absolute_risk_difference - z95*SE_proportions_diff, absolute_risk_difference + z95*SE_proportions_diff)\n",
    "proportions_diff_95CI_pretty = ('{0:.10f}'.format(proportions_diff_95CI[0]*100)+\" %\", '{0:.10f}'.format(proportions_diff_95CI[1]*100)+\" %\")\n",
    "print(f\"proportions_diff_95CI = {proportions_diff_95CI_pretty}\")\n",
    "proportions_diff_99CI = (absolute_risk_difference - z99*SE_proportions_diff, absolute_risk_difference + z99*SE_proportions_diff)\n",
    "proportions_diff_99CI_pretty = ('{0:.10f}'.format(proportions_diff_99CI[0]*100)+\" %\", '{0:.10f}'.format(proportions_diff_99CI[1]*100)+\" %\")\n",
    "print(f\"proportions_diff_99CI = {proportions_diff_99CI_pretty}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-ozone",
   "metadata": {},
   "source": [
    "The p-value for getting total of 4 cases from total of 43'448 people is $0.259\\%$\n",
    "\n",
    "Then, from that, there's $1$ in $2^4$ probability of getting all these cases in a one specific group only by chance, that is $\\frac{1}{2^4} = \\frac{1}{16} = 0.0625 = 6.25\\%$. Therefore, the fact that 4 cases were in one group and 0 in another is a statistically insignificant indicator of significant inclination towards vaccine group. This is also idicated with 95%CI of the difference between two proportions almost touching 0, and 99%CI including it.\n",
    "\n",
    "On the other hand, the plain fact itself that 4 cases took place during the study is a significant indicator of the presence of the effect:\n",
    "\n",
    "$pvalue_{total} = 0.2589\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-blackberry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kt=k1+k2\n",
    "nt=n1+n2\n",
    "pt=INCIDENCE_biased/6 # assuming their study had average 2 months of screening\n",
    "\n",
    "print(f\"                        kt = {kt}\")\n",
    "print(f\"                        nt = {nt}\")\n",
    "print(f\"                        pt = {round(pt*100, 5)}%\")\n",
    "print(\"\")\n",
    "\n",
    "expectedt = nt*pt\n",
    "print(f\"    expected value = nt*pt = {round(expectedt, 4)}\")\n",
    "\n",
    "# scipy\n",
    "pvalt = stats.binom_test(x=kt, n=nt, p=pt)\n",
    "print(f\"(scipy)              pvalt = {round(pvalt*100, 4)}%\")\n",
    "\n",
    "# naive (binomial test)\n",
    "pvalt = math.comb(nt, kt) * math.pow(pt,kt) * math.pow(1-pt,nt-kt)\n",
    "print(f\"(naive, binom. test) pvalt = {round(pvalt*100, 4)}%\")\n",
    "\n",
    "proportion_t = kt/nt\n",
    "s_errort = math.sqrt((proportion_t*(1-proportion_t))/nt) # standard error for proportion\n",
    "print(f\"                  s_errort = {round(s_errort,7)}\")\n",
    "\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-kentucky",
   "metadata": {},
   "source": [
    "## VI. Calculate different effect size formulas to show practical significance of the effect. Some: relative risk, absolute risk difference, number needed to vaccinate, odds ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-think",
   "metadata": {},
   "source": [
    "To calculate various effect size formulas, we'll use expected value for the placebo group event rate\n",
    "\n",
    "$biased\\,incidence \\times n_{placebo} = 0.00128\\% \\times 21728 = 0.2788$\n",
    "\n",
    "intead of actual observed $0$ cases\n",
    "\n",
    "\n",
    "Thus, instead of this data:\n",
    "\n",
    "| Group        | had Bell's palsy ($k_i$) | didn't have ($n_i - k_i$) | total ($n_i$) |\n",
    "| ------------ |:------------------------:|:-------------------------:|:-------------:|\n",
    "| vaccine      |             4            |           21716           |     21720     |\n",
    "| placebo      |             0            |           21728           |     21728     |\n",
    "\n",
    "\n",
    "we'll use this corrected one:\n",
    "\n",
    "| Group        | had Bell's palsy ($k_i$) | didn't have ($n_i - k_i$) | total ($n_i$) |\n",
    "| ------------ |:------------------------:|:-------------------------:|:-------------:|\n",
    "| vaccine      |             4            |           21716           |     21720     |\n",
    "| placebo      |           0.2788         |           21727.7212      |     21728     |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-aspect",
   "metadata": {},
   "source": [
    "vaccine (experimental) group event rate:\n",
    "\n",
    "$r_1 = \\frac{4}{21720} = 0.000184 = 0.0184\\%$\n",
    "\n",
    "placebo (control) group event rate:\n",
    "\n",
    "$r_2 = \\frac{0.2788}{21728} = 0.0000128 = 0.00128\\%$\n",
    "\n",
    "<br>\n",
    "\n",
    "relative risk of bell's palsy (the ratio of the experimental event rate to the control event rate):\n",
    "\n",
    "$\\frac{r_1}{r_2} = \\frac{0.0184\\%}{0.00128\\%} = 14.375 = 1437.5\\%$\n",
    "\n",
    "absolute risk difference (the difference between risks, the difference between experimental event rate to the control event rate):\n",
    "\n",
    "$r_1 - r_2 = 0.0184\\% - 0.00128\\% = 0.01712\\% = 0.0001712$\n",
    "\n",
    "Therefore, having the vaccine increases changes of getting Bell's palsy by $1437.5\\%$ (i.e. $14.375$ times), that is plus $0.01712\\%$ in absolute\n",
    "\n",
    "<br>\n",
    "\n",
    "number of patients needed to vaccinate to cause 1 incidence of Bell's palsy (1 divided by absolute risk difference):\n",
    "\n",
    "$\\frac{1}{0.0001712} = 5841.12$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-impossible",
   "metadata": {},
   "source": [
    "## Sources:\n",
    " - https://www.who.int/medicines/technical_briefing/tbs/03-PG_Assessing-drug-efficacy_final-08.pdf (specifically, pages 23-27)\n",
    " - https://online.stat.psu.edu/stat100/book/export/html/678\n",
    " - https://towardsdatascience.com/five-confidence-intervals-for-proportions-that-you-should-know-about-7ff5484c024f\n",
    " - Wallis, Sean A. (2013). \"Binomial confidence intervals and contingency tests: mathematical fundamentals and the evaluation of alternative methods\" [(PDF)](https://www.ucl.ac.uk/english-usage/staff/sean/resources/binomialpoisson.pdf). Journal of Quantitative Linguistics. 20 (3): 178–208. doi:10.1080/09296174.2013.799918."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
